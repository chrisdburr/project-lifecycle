---
title: Introduction
author: Ethics and Responsible Innovation Team, Alan Turing Institute
hide:
  - navigation
  - toc
---

# Introduction

['Anatomy of an AI system'](https://anatomyof.ai/) is a visual schematic of an AI system by Kate Crawford and Vladan Joler, which captures the far-reaching and expansive effects of artificial intelligence (AI) development. Although they use an Amazon Echo device as their illustrative example, the graphic renders and makes manifest the scale of AI technologies more generally. Distribution, assembly, and manufacturing chains; domestic and information infrastructure; geological processes; content providers and internet platforms; and skilled and unskilled human labour. All of these domains, and many more, are linked together and subsumed by Crawford and Joler's impressive model.

In a singular image, the expansive reach of an AI project is laid bare, exposing the myriad sectors and domains that are affected by the pursuit of technological innovation, and the interdependence of artificial *intelligence* on existing sociocultural practices and institutions.

<iframe src="https://anatomyof.ai/img/ai-anatomy-map.pdf" width="100%" height="500px"></iframe>

However, as the oft-quoted phrase, "all models are wrong, but some are useful", emphasises, there are limits to what any individual model can achieve. And, like most models, 'Anatomy of an AI System' is designed to support a specific goal or set of objectives, such as representing a physical or sociological process to enable greater theoretical understanding. If 'Anatomy of an AI System' were to be used as a model to help regulators and policy-makers identify and evaluate the most salient activities of a typical AI lifecycle, it would likely cause many to miss the forest for the trees. Therefore, a more tailored model is necessary to support regulators and policy-makers.

Such a model should be able to strike a delicate (or, fragile) balance between, on the one hand, the high-level perspective necessary for regulating technology chains with global reach, and on the other hand, the lower-level and detail-orientated perspective required to understand complex, data-driven technologies. The model we present in this guidance achieves this balance, while also serving several additional and vital policy objectives.

From the outset, our model of the AI project lifecycle was designed to meet the following, interlocking objectives:

1. Provide a clear and accessible representation of a typical AI project lifecycle, which has both a high-level of technical accuracy but is also flexible across different domains and organisations (e.g., applicable to both SMEs and multi-national corporations).
2. Support the identification of a) salient regulatory touchpoints, b) value chains and routes to market, and c) legal considerations.
3. Facilitate ongoing discussion into and assessment of legislative and regulatory gaps.
4. Build on existing guidance and best practices in a consistent and complementary manner.
5. Promotes a more responsible and ethical approach to the design, development, and deployment of AI systems, by embedding a bias-aware and human rights focused methodology into the project lifecycle.

The following pages introduces the AI project lifecycle and the constituent stages and activities before turning to a discussion and exploration of how this model facilitates the identification of salient regulatory touchpoints.
